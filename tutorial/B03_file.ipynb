{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpDB Manual之系列3：处理非结构化及半结构化数据文件"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SpDB** 处理Python中非结构化数据,如GDSKfile等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spdm.data.File import File\n",
    "from spdm.utils.logger import logger\n",
    "from pathlib import Path\n",
    "current_path = \"/scratch/jupytertest/workspace_fytok/fytok_tutorial/tutorial\"\n",
    "### For NameList File\n",
    "DATA_INPUT = current_path+\"/data/\"\n",
    "with File(DATA_INPUT+\"/g070754.05000\", mode=\"r\", format=\"GEQdsk\") as fid:\n",
    "    doc = fid.read()\n",
    "    eq_test = doc.dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['wall', 'equilibrium'])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### eq_test是Python中的字典，其key遵守IMAS IDS的组织结构\n",
    "eq_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time', 'vacuum_toroidal_field', 'time_slice'])"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### 查看equilibrium中的数据\n",
    "eq_test[\"equilibrium\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **SpDB** 访问Python中半结构化数据,如NameList,netCDF,HDF5等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 初始化环境\n",
    "from spdm.data.File import File\n",
    "from spdm.utils.logger import logger\n",
    "from pathlib import Path\n",
    "current_path = \"/scratch/jupytertest/workspace_fytok/fytok_tutorial/tutorial\"\n",
    "### For NameList File\n",
    "DATA_INPUT = current_path+\"/data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **NameList**文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###以GENRAY的输入文件genray.dat为例，它是一个NameList格式的文件。\n",
    "with File(f\"{DATA_INPUT}/genray.dat\", format= \"namelist\" ,mode=\"r\") as oid:\n",
    "### 仅仅建立链接，而没有拿回数据\n",
    "    output_entry = oid.read()\n",
    "### 拿回所有数据\n",
    "    output_data = oid.read().dump()\n",
    "###获取namelist中的关键字key\n",
    "logger.info(output_data.keys())\n",
    "### 通过child获取某个子节点的值，而不需要把整个树读回来\n",
    "logger.info(output_entry.child(\"main_lobes\").__value__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-11-11 16:09:18,263 [    spdm]     INFO: dict_keys(['main_lobes', 'genr', 'tokamak', 'wave', 'scatnper', 'dispers', 'numercl', 'output', 'plasma', 'species', 'varden', 'denprof', 'tpopprof', 'vflprof', 'zprof', 'tprof', 'grill', 'rz_launch_grill_tab', 'eccone', 'dentab', 'dentab_nonuniform_line', 'temtab', 'temtab_nonuniform_line', 'tpoptab', 'tpoptab_nonuniform_line', 'vflowtab', 'vflowtab_nonuniform_line', 'zeftab', 'zeftab_nonuniform_line', 'read_diskf', 'emission', 'ox', 'adj_nml', 'edge_prof_nml', 'lsc_approach_nml', 'edctsctab', 'jpartsctab'])\u001b[0m\n",
      "\u001b[0;34m2023-11-11 16:09:18,265 [    spdm]     INFO: OrderedDict([('total_grills', 5),\n",
      "             ('main_grills', 4),\n",
      "             ('bt_direction', 1),\n",
      "             ('power_fraction_factor', 0.8248)])\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "###获取namelist中的关键字key\n",
    "logger.info(output_data.keys())\n",
    "### 通过child获取某个子节点的值，而不需要把整个树读回来\n",
    "logger.info(output_entry.child(\"main_lobes\").__value__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### NotImplementedError: TODO: NAMELISTFile.write\n",
    "# with File(f\"{DATA_INPUT}/test-eq.h5\", mode=\"w\", format=\"namelist\") as oid:\n",
    "#     oid.write(eq_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **netCDF**文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-11-11 16:09:53,906 [    spdm]     INFO: dict_keys(['charge', 'dmass', 'en', 'eqdsk_name', 'nj', 'nspecgr', 'r', 'temp', 'zeff', 'title'])\u001b[0m\n",
      "\u001b[0;34m2023-11-11 16:09:53,907 [    spdm]     INFO: [1.00000000e+00 1.83619995e+03 3.67239990e+03 2.20343994e+04]\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### 以GENRAY的剖面输入文件genray_profs_in.nc为例，它是一个netCDF格式的文件。\n",
    "with File(f\"{DATA_INPUT}/genray_profs_in.nc\", format= \"NetCDf\" ,mode=\"r\") as oid:\n",
    "### 仅仅建立链接，而没有拿回数据\n",
    "    output_entry = oid.read()\n",
    "### 拿回所有数据\n",
    "    output_data = oid.read().dump()\n",
    "###获取namelist中的关键字key\n",
    "logger.info(output_data.keys())\n",
    "logger.info(output_data[\"dmass\"].data)\n",
    "### 通过child获取某个子节点的值，而不需要把整个树读回来\n",
    "# logger.info(output_entry.child(\"dmass\").__value__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-11-11 16:10:01,846 [    spdm]     INFO: dict_keys(['wall', 'equilibrium'])\u001b[0m\n",
      "\u001b[0;34m2023-11-11 16:10:01,847 [    spdm]     INFO: {'description_2d': {'0': {'limiter': {'unit': {'0': {'outline': {'r': array([1.35838, 1.35838, 1.35838, 1.36314, 1.4371 , 1.43721, 1.44164,\n",
      "       1.4297 , 1.39169, 1.39151, 1.37929, 1.399  , 1.43623, 1.45919,\n",
      "       1.47791, 1.54494, 1.61204, 1.63506, 1.66054, 1.66519, 1.6955 ,\n",
      "       1.70668, 1.71388, 1.714  , 1.73649, 1.76324, 1.80199, 1.80237,\n",
      "       1.93972, 1.97063, 2.07495, 2.1771 , 2.27925, 2.35   , 2.35   ,\n",
      "       2.35   , 2.27925, 2.1771 , 2.07495, 1.9728 , 1.97063, 1.92059,\n",
      "       1.87055, 1.82051, 1.79281, 1.76511, 1.75421, 1.67782, 1.60143,\n",
      "       1.48426, 1.36709, 1.33132, 1.37874, 1.42615, 1.40528, 1.3844 ,\n",
      "       1.36353, 1.35838, 1.35838, 1.35838, 1.35838]),\n",
      "                                                                 'z': array([ 0.      ,  0.227   ,  0.454   ,  0.455735,  0.798332,  0.798821,\n",
      "        0.838195,  0.908908,  1.01426 ,  1.01473 ,  1.04859 ,  1.03946 ,\n",
      "        1.0256  ,  1.02095 ,  1.02514 ,  1.05454 ,  1.08394 ,  1.09586 ,\n",
      "        1.114   ,  1.11765 ,  1.14183 ,  1.16211 ,  1.13093 ,  1.13044 ,\n",
      "        1.033   ,  0.969832,  0.92567 ,  0.925347,  0.809223,  0.783389,\n",
      "        0.68838 ,  0.58904 ,  0.4897  ,  0.49    ,  0.      , -0.49    ,\n",
      "       -0.4897  , -0.58904 , -0.68838 , -0.78772 , -0.783389, -0.832375,\n",
      "       -0.881361, -0.930347, -1.05034 , -1.17034 , -1.13917 , -1.03465 ,\n",
      "       -0.930138, -0.95338 , -0.976622, -1.01072 , -0.879327, -0.747939,\n",
      "       -0.65062 , -0.5533  , -0.455981, -0.454   , -0.227   ,  0.      ,\n",
      "        0.      ])}}}}}}}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### 写.nc文件\n",
    "with File(f\"{DATA_INPUT}/test-eq.nc\", mode=\"w\", format=\"netcdf\") as oid:\n",
    "    oid.write(eq_test)\n",
    "with File(f\"{DATA_INPUT}/test-eq.nc\", format= \"NetCDf\" ,mode=\"r\") as oid: \n",
    "    test_data = oid.read().dump()\n",
    "    logger.info(test_data.keys())\n",
    "    logger.info(test_data[\"wall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **HDF5**文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-11-11 16:10:15,353 [    spdm]     INFO: dict_keys(['coherent_wave'])\u001b[0m\n",
      "\u001b[0;34m2023-11-11 16:10:15,354 [    spdm]     INFO: {'current_tor': 461821.31203568814,\n",
      " 'frequency': 4600000000.0,\n",
      " 'power': 19375694355948.902}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### 以testall.h5，它是一个HDF5格式的文件。\n",
    "with File(f\"{DATA_INPUT}/testall.h5\", format= \"HDF5\" ,mode=\"r\") as oid:\n",
    "### 仅仅建立链接，而没有拿回数据\n",
    "    output_entry = oid.read()\n",
    "### 拿回所有数据\n",
    "    output_data = oid.read().dump()\n",
    "###获取namelist中的关键字key\n",
    "logger.info(output_data.keys())\n",
    "logger.info(output_data[\"coherent_wave\"][\"global_quantities\"])\n",
    "\n",
    "### 通过child获取某个子节点的值，而不需要把整个树读回来\n",
    "# logger.info(output_entry.child(\"coherent_wave.current_tor\").__value__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;34m2023-11-11 16:10:22,676 [    spdm]     INFO: dict_keys(['equilibrium', 'wall'])\u001b[0m\n",
      "\u001b[0;34m2023-11-11 16:10:22,677 [    spdm]     INFO: {'description_2d': [{'limiter': {'unit': [{'outline': {'r': array([1.35838, 1.35838, 1.35838, 1.36314, 1.4371 , 1.43721, 1.44164,\n",
      "       1.4297 , 1.39169, 1.39151, 1.37929, 1.399  , 1.43623, 1.45919,\n",
      "       1.47791, 1.54494, 1.61204, 1.63506, 1.66054, 1.66519, 1.6955 ,\n",
      "       1.70668, 1.71388, 1.714  , 1.73649, 1.76324, 1.80199, 1.80237,\n",
      "       1.93972, 1.97063, 2.07495, 2.1771 , 2.27925, 2.35   , 2.35   ,\n",
      "       2.35   , 2.27925, 2.1771 , 2.07495, 1.9728 , 1.97063, 1.92059,\n",
      "       1.87055, 1.82051, 1.79281, 1.76511, 1.75421, 1.67782, 1.60143,\n",
      "       1.48426, 1.36709, 1.33132, 1.37874, 1.42615, 1.40528, 1.3844 ,\n",
      "       1.36353, 1.35838, 1.35838, 1.35838, 1.35838]),\n",
      "                                                       'z': array([ 0.      ,  0.227   ,  0.454   ,  0.455735,  0.798332,  0.798821,\n",
      "        0.838195,  0.908908,  1.01426 ,  1.01473 ,  1.04859 ,  1.03946 ,\n",
      "        1.0256  ,  1.02095 ,  1.02514 ,  1.05454 ,  1.08394 ,  1.09586 ,\n",
      "        1.114   ,  1.11765 ,  1.14183 ,  1.16211 ,  1.13093 ,  1.13044 ,\n",
      "        1.033   ,  0.969832,  0.92567 ,  0.925347,  0.809223,  0.783389,\n",
      "        0.68838 ,  0.58904 ,  0.4897  ,  0.49    ,  0.      , -0.49    ,\n",
      "       -0.4897  , -0.58904 , -0.68838 , -0.78772 , -0.783389, -0.832375,\n",
      "       -0.881361, -0.930347, -1.05034 , -1.17034 , -1.13917 , -1.03465 ,\n",
      "       -0.930138, -0.95338 , -0.976622, -1.01072 , -0.879327, -0.747939,\n",
      "       -0.65062 , -0.5533  , -0.455981, -0.454   , -0.227   ,  0.      ,\n",
      "        0.      ])}}]}}]}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#### 写.nc文件\n",
    "with File(f\"{DATA_INPUT}/test-eq.hdf5\", mode=\"w\", format=\"HDF5\") as oid:\n",
    "    oid.write(eq_test)\n",
    "with File(f\"{DATA_INPUT}/test-eq.hdf5\", format= \"HDF5\" ,mode=\"r\") as oid: \n",
    "    test_data = oid.read().dump()\n",
    "    logger.info(test_data.keys())\n",
    "    logger.info(test_data[\"wall\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注：（1）其他的半结构化数据,YAML,JSON等，访问形式类似。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
